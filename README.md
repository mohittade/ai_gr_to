# AI-Based Language Translation with Attention Mechanisms
## German â†’ English â†’ Marathi Translation System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/Transformers-4.30+-yellow.svg)](https://huggingface.co/transformers/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Overview

This project implements a state-of-the-art Neural Machine Translation (NMT) system for translating from **German â†’ English â†’ Marathi** using Transformer models with attention mechanisms. The system leverages deep learning advances to provide accurate, contextually-aware multilingual translation, particularly focusing on the low-resource language pair German-Marathi.

### Key Features

- âœ… **Transformer Architecture**: Self-attention and multi-head attention mechanisms
- âœ… **Pipeline Translation**: German â†’ English â†’ Marathi with intermediate outputs
- âœ… **Attention Mechanisms**: Context-aware word-level alignment
- âœ… **Low-Resource Support**: Optimized for Marathi translation
- âœ… **REST API**: Real-time translation endpoint
- âœ… **Evaluation Metrics**: BLEU and METEOR scoring
- âœ… **Production Ready**: Scalable deployment with FastAPI

## ğŸ—ï¸ Architecture

The system consists of two sequential Transformer models:

```
German Text â†’ [Encoder-Decoder 1] â†’ English Text â†’ [Encoder-Decoder 2] â†’ Marathi Text
                  (DEâ†’EN Model)                        (ENâ†’MR Model)
```

### Transformer Components

1. **Encoder**: Processes input sequence with self-attention
2. **Decoder**: Generates output sequence with cross-attention
3. **Multi-Head Attention**: Learns multiple semantic relationships
4. **Positional Encoding**: Maintains sequence order information
5. **Feed-Forward Networks**: Non-linear transformations

![Transformer Architecture](docs/architecture.png)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (optional, but recommended)
- 8GB+ RAM

### Installation

```bash
# Clone the repository
git clone https://github.com/mohittade/ai_gr_to.git
cd ai_gr_to

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

#### 1. Data Preprocessing

```python
from utils.preprocessing import DataPreprocessor, BilingualDataset

# Initialize preprocessor
preprocessor = DataPreprocessor(config={
    'max_length': 128,
    'min_length': 3
})

# Load and preprocess data
dataset = BilingualDataset(
    source_file='data/german.txt',
    target_file='data/english.txt',
    preprocessor=preprocessor
)
```

#### 2. Training Models

```python
from training.train import Trainer, Transformer
from torch.utils.data import DataLoader

# Configuration
config = {
    'd_model': 512,
    'num_heads': 8,
    'num_encoder_layers': 6,
    'num_decoder_layers': 6,
    'd_ff': 2048,
    'dropout': 0.1,
    'batch_size': 32,
    'num_epochs': 30
}

# Create model
model = Transformer(
    src_vocab_size=32000,
    tgt_vocab_size=32000,
    **config
)

# Train
trainer = Trainer(model, train_loader, val_loader, config)
trainer.train(num_epochs=30)
```

#### 3. Translation

```python
from api.api_server import TranslationPipeline

# Initialize pipeline
pipeline = TranslationPipeline()
pipeline.load_models(
    de_en_path='models/de_en_model.pt',
    en_mr_path='models/en_mr_model.pt'
)

# Translate
german_text = "Guten Morgen, wie geht es Ihnen?"
marathi_text, english_intermediate = pipeline.translate_de_to_mr(german_text)

print(f"German: {german_text}")
print(f"English (intermediate): {english_intermediate}")
print(f"Marathi: {marathi_text}")
```

#### 4. Evaluation

```python
from evaluation.metrics import TranslationEvaluator

evaluator = TranslationEvaluator()

hypotheses = ["translated sentence 1", "translated sentence 2"]
references = ["reference translation 1", "reference translation 2"]

# Evaluate
results = evaluator.evaluate(hypotheses, references)
print(f"BLEU Score: {results['corpus_bleu']:.4f}")
print(f"METEOR Score: {results['avg_meteor']:.4f}")

# Generate report
report = evaluator.generate_evaluation_report(hypotheses, references)
print(report)
```

### REST API Usage

#### Start the API Server

```bash
# Run the FastAPI server
python api/api_server.py

# Or using uvicorn directly
uvicorn api.api_server:app --host 0.0.0.0 --port 8000 --reload
```

#### API Endpoints

**Translate Text**
```bash
curl -X POST "http://localhost:8000/translate" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Guten Morgen",
    "source_lang": "de",
    "target_lang": "mr"
  }'
```

**Batch Translation**
```bash
curl -X POST "http://localhost:8000/batch-translate" \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["Hallo", "Danke"],
    "source_lang": "de",
    "target_lang": "mr"
  }'
```

**Health Check**
```bash
curl http://localhost:8000/health
```

**Interactive Documentation**
Visit `http://localhost:8000/docs` for interactive API documentation powered by Swagger UI.

## ğŸ“Š Model Performance

| Metric | DEâ†’EN | ENâ†’MR | DEâ†’MR (Pipeline) |
|--------|-------|-------|------------------|
| BLEU-4 | 0.XX  | 0.XX  | 0.XX            |
| METEOR | 0.XX  | 0.XX  | 0.XX            |

*Note: Scores will be updated after training on full datasets*

## ğŸ“ Project Structure

```
ai_gr_to/
â”œâ”€â”€ data/                   # Training and test datasets
â”‚   â”œâ”€â”€ german_english/     # German-English parallel corpus
â”‚   â””â”€â”€ english_marathi/    # English-Marathi parallel corpus
â”œâ”€â”€ models/                 # Model implementations
â”‚   â””â”€â”€ transformer.py      # Transformer architecture
â”œâ”€â”€ training/               # Training scripts
â”‚   â””â”€â”€ train.py           # Training pipeline
â”œâ”€â”€ evaluation/            # Evaluation metrics
â”‚   â””â”€â”€ metrics.py         # BLEU, METEOR implementation
â”œâ”€â”€ api/                   # REST API
â”‚   â””â”€â”€ api_server.py      # FastAPI server
â”œâ”€â”€ utils/                 # Utilities
â”‚   â””â”€â”€ preprocessing.py   # Data preprocessing
â”œâ”€â”€ checkpoints/           # Model checkpoints
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

## ğŸ”¬ Technical Details

### Attention Mechanism

The multi-head attention mechanism allows the model to focus on different parts of the input sequence:

```python
Attention(Q, K, V) = softmax(QK^T / âˆšd_k)V
```

Where:
- Q (Query): What we're looking for
- K (Key): What we're looking at
- V (Value): The actual information
- d_k: Dimension scaling factor

### Preprocessing Pipeline

1. **Text Cleaning**: Remove URLs, emails, special characters
2. **Normalization**: Unicode normalization, lowercasing, punctuation standardization
3. **Tokenization**: Byte Pair Encoding (BPE) for subword segmentation
4. **Alignment**: Validate parallel sentence pairs

### Training Strategy

- **Optimizer**: Adam with Î²â‚=0.9, Î²â‚‚=0.98, Îµ=1e-9
- **Learning Rate**: Warmup for 4000 steps, then decay
- **Regularization**: Label smoothing (0.1), dropout (0.1)
- **Batch Size**: Dynamic batching for GPU utilization
- **Loss Function**: Cross-entropy with label smoothing

## ğŸ“š Datasets

### German-English
- **Europarl**: European Parliament proceedings
- **OPUS**: Open parallel corpus
- **Size**: ~1M sentence pairs

### English-Marathi
- **IIT Bombay Corpus**: English-Hindi-Marathi
- **OPUS**: Various sources
- **Size**: ~50K sentence pairs

## ğŸ¯ Use Cases

- **Education**: Translate German academic content to Marathi
- **Healthcare**: Medical document translation
- **Business**: Cross-cultural communication
- **Research**: Multilingual knowledge sharing
- **Digital Content**: Website and app localization

## ğŸ› ï¸ Development

### Running Tests

```bash
# Test preprocessing
python utils/preprocessing.py

# Test model architecture
python models/transformer.py

# Test evaluation metrics
python evaluation/metrics.py
```

### Training from Scratch

```bash
# 1. Prepare data
python utils/preprocessing.py --input data/raw --output data/processed

# 2. Train Germanâ†’English model
python training/train.py --config configs/de_en_config.json

# 3. Train Englishâ†’Marathi model
python training/train.py --config configs/en_mr_config.json

# 4. Evaluate
python evaluation/metrics.py --model checkpoints/best_model.pt
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“– Citation

If you use this system in your research, please cite:

```bibtex
@article{raina2024german_marathi_translation,
  title={AI-Based Language Translation with Attention Mechanisms: German to English to Marathi},
  author={Raina, Ricky and Londhe, Aryan and Dhole, Aditi and Salve, Shreya},
  journal={Information Technology Department, JSPM's Rajarshi Shahu College of Engineering},
  year={2024}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Ricky Raina** - [Email](mailto:Rickyraina11@gmail.com)
- **Aryan Londhe** - [Email](mailto:londhearyan21@gmail.com)
- **Aditi Dhole** - [Email](mailto:dholeaditi56@gmail.com)
- **Shreya Salve** - [Email](mailto:Salveshreya.official@gmail.com)

**Supervisor**: Dr. Archana Jadhav

**Institution**: JSPM's Rajarshi Shahu College of Engineering, Tathawade, Pune, India

## ğŸ™ Acknowledgments

- Based on "Attention Is All You Need" (Vaswani et al., 2017)
- HuggingFace Transformers library
- PyTorch team
- OPUS and Europarl dataset contributors
- IIT Bombay for English-Marathi corpus

## ğŸ“ Contact

For questions or collaborations, please contact:
- Email: Rickyraina11@gmail.com
- GitHub: [@mohittade](https://github.com/mohittade)

---

**Status**: ğŸŸ¢ Active Development | **Version**: 1.0.0 | **Last Updated**: November 2024
